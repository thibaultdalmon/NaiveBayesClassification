{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(texts):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    words = set()\n",
    "    vocabulary = {}\n",
    "    table = str.maketrans({key:\" \" for key in string.punctuation})\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for text in texts:\n",
    "        word_list = text.translate(table).lower().split(\" \")\n",
    "        for word in word_list:\n",
    "            if word not in words:\n",
    "                words.add(word)\n",
    "                vocabulary[word] = j\n",
    "                j += 1\n",
    "\n",
    "    n_features = len(words)\n",
    "    counts = np.zeros((len(texts), n_features))\n",
    "\n",
    "    for text in texts:\n",
    "        word_list = text.translate(table).lower().split(\" \")\n",
    "        for word in word_list:\n",
    "            if word in words:\n",
    "                counts[i][vocabulary[word]] += 1\n",
    "        i += 1\n",
    "\n",
    "    return vocabulary, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.prior = np.zeros((2))\n",
    "        self.condprob = None\n",
    "        self.scores = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.condprob = np.zeros((2, X.shape[1]))\n",
    "        for c in [0,1]:\n",
    "            self.prior[c] = X[y==c].shape[0] / X.shape[0]\n",
    "            self.condprob[c,:] = ((np.sum(X[y==c], axis=0) +1)\n",
    "                / np.sum(np.sum(X[y==c], axis=1)+1))\n",
    "        return self.vocabulary, self.prior, self.condprob\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.scores = np.zeros((X.shape[0], self.prior.shape[0]))\n",
    "        self.scores += np.log(self.prior)\n",
    "        tmp = np.zeros((X.shape[0], X.shape[1], 2))\n",
    "        for c in [0,1]:\n",
    "            tmp[:,:,c] = np.multiply(X, self.condprob[c,:])\n",
    "        tmp[tmp==0] = 1\n",
    "        self.scores += np.sum(np.log(tmp), axis=1)\n",
    "        return np.argmax(self.scores, axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "# Count words in text\n",
    "vocabulary, X = count_words(texts)\n",
    "\n",
    "# Try to fit, predict and score\n",
    "nb = NB(vocabulary)\n",
    "nb.fit(X[::2], y[::2])\n",
    "print (nb.score(X[1::2], y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "0.8\n",
      "0.7975\n",
      "0.7825\n",
      "0.735\n",
      "0.779\n"
     ]
    }
   ],
   "source": [
    "# Try to fit, predict and score using cross-validation 5-folds\n",
    "X_dict = {}\n",
    "y_dict = {}\n",
    "for i in range(5):\n",
    "    X_dict[f\"X_{i}\"] = X[i::5]\n",
    "    y_dict[f\"y_{i}\"] = y[i::5]\n",
    "\n",
    "score = 0\n",
    "for i in range(5):\n",
    "    nb = NB(vocabulary)\n",
    "    X_val = X_dict[f\"X_{i}\"]\n",
    "    y_val = y_dict[f\"y_{i}\"]\n",
    "    first = True\n",
    "    for j in range(5):\n",
    "        if (j!=i):\n",
    "            if bool:\n",
    "                first = False\n",
    "                X_train = X_dict[f\"X_{j}\"]\n",
    "                y_train = y_dict[f\"y_{j}\"]\n",
    "            else:\n",
    "                X_train = np.concatenate((X_train, X_dict[f\"X_{j}\"]), axis=0)\n",
    "                y_train = np.concatenate((y_train, y_dict[f\"y_{j}\"]), axis=0)\n",
    "    nb.fit(X_train, y_train)\n",
    "    score_tmp = nb.score(X_val, y_val)\n",
    "    print(score_tmp)\n",
    "    score += score_tmp\n",
    "print(score/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_V2(texts):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    words = set()\n",
    "    vocabulary = {}\n",
    "    table = str.maketrans({key:\" \" for key in string.punctuation})\n",
    "    i = 0\n",
    "    j = 0\n",
    "    english_words = open(op.join('data', 'english.stop')).read()\n",
    "\n",
    "    for text in texts:\n",
    "        word_list = text.translate(table).lower().split(\" \")\n",
    "        for word in word_list:\n",
    "            if (word not in words) and (word not in english_words):\n",
    "                words.add(word)\n",
    "                vocabulary[word] = j\n",
    "                j += 1\n",
    "\n",
    "    n_features = len(words)\n",
    "    counts = np.zeros((len(texts), n_features))\n",
    "\n",
    "    for text in texts:\n",
    "        word_list = text.translate(table).lower().split(\" \")\n",
    "        for word in word_list:\n",
    "            if word in words:\n",
    "                counts[i][vocabulary[word]] += 1\n",
    "        i += 1\n",
    "\n",
    "    return vocabulary, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808\n"
     ]
    }
   ],
   "source": [
    "# Count words in text\n",
    "vocabulary, X = count_words_V2(texts)\n",
    "\n",
    "# Try to fit, predict and score\n",
    "nb = NB(vocabulary)\n",
    "nb.fit(X[::2], y[::2])\n",
    "print (nb.score(X[1::2], y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.79\n",
      "0.765\n",
      "0.77\n",
      "0.72\n",
      "0.759\n"
     ]
    }
   ],
   "source": [
    "# Try to fit, predict and score using cross-validation 5-folds\n",
    "X_dict = {}\n",
    "y_dict = {}\n",
    "for i in range(5):\n",
    "    X_dict[f\"X_{i}\"] = X[i::5]\n",
    "    y_dict[f\"y_{i}\"] = y[i::5]\n",
    "\n",
    "score = 0\n",
    "for i in range(5):\n",
    "    nb = NB(vocabulary)\n",
    "    X_val = X_dict[f\"X_{i}\"]\n",
    "    y_val = y_dict[f\"y_{i}\"]\n",
    "    first = True\n",
    "    for j in range(5):\n",
    "        if (j!=i):\n",
    "            if bool:\n",
    "                first = False\n",
    "                X_train = X_dict[f\"X_{j}\"]\n",
    "                y_train = y_dict[f\"y_{j}\"]\n",
    "            else:\n",
    "                X_train = np.concatenate((X_train, X_dict[f\"X_{j}\"]), axis=0)\n",
    "                y_train = np.concatenate((y_train, y_dict[f\"y_{j}\"]), axis=0)\n",
    "    nb.fit(X_train, y_train)\n",
    "    score_tmp = nb.score(X_val, y_val)\n",
    "    print(score_tmp)\n",
    "    score += score_tmp\n",
    "print(score/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with sklearn\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.813"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = texts[::2], y[::2]\n",
    "X_test, y_test = texts[1::2], y[1::2]\n",
    "countVec = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "cV_mNB = Pipeline([('countVec', countVec), ('multNB', clf)])\n",
    "cV_mNB.set_params().fit(X_train, y_train)\n",
    "cV_mNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = texts[::2], y[::2]\n",
    "X_test, y_test = texts[1::2], y[1::2]\n",
    "countVec = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "cV_mNB = Pipeline([('countVec', countVec), ('multNB', clf)])\n",
    "cV_mNB.set_params(countVec__analyzer = \"char\").fit(X_train, y_train)\n",
    "cV_mNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = texts[::2], y[::2]\n",
    "X_test, y_test = texts[1::2], y[1::2]\n",
    "countVec = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "cV_mNB = Pipeline([('countVec', countVec), ('multNB', clf)])\n",
    "cV_mNB.set_params(countVec__analyzer = \"char_wb\").fit(X_train, y_train)\n",
    "cV_mNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/thibault/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/thibault/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk import SnowballStemmer, pos_tag, word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = texts[::2], y[::2]\n",
    "X_test, y_test = texts[1::2], y[1::2]\n",
    "countVec = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "cV_mNB = Pipeline([('countVec', countVec), ('logReg', clf)])\n",
    "cV_mNB.set_params(logReg__random_state=42, logReg__solver='liblinear').fit(X_train, y_train)\n",
    "cV_mNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = texts[::2], y[::2]\n",
    "X_test, y_test = texts[1::2], y[1::2]\n",
    "countVec = CountVectorizer()\n",
    "clf = LinearSVC()\n",
    "cV_mNB = Pipeline([('countVec', countVec), ('linSVC', clf)])\n",
    "cV_mNB.set_params(linSVC__random_state=42, linSVC__max_iter=10000).fit(X_train, y_train)\n",
    "cV_mNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "texts_stemmed = []\n",
    "for text in texts:\n",
    "    text_stemmed = \"\"\n",
    "    for word in text.split(\" \"):\n",
    "        text_stemmed += stemmer.stem(word) + \" \"\n",
    "    texts_stemmed.append(text_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = texts_stemmed[::2], y[::2]\n",
    "X_test, y_test = texts_stemmed[1::2], y[1::2]\n",
    "countVec = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "cV_mNB = Pipeline([('countVec', countVec), ('logReg', clf)])\n",
    "cV_mNB.set_params(logReg__random_state=42, logReg__solver='liblinear').fit(X_train, y_train)\n",
    "cV_mNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = texts_stemmed[::2], y[::2]\n",
    "X_test, y_test = texts_stemmed[1::2], y[1::2]\n",
    "countVec = CountVectorizer()\n",
    "clf = LinearSVC()\n",
    "cV_mNB = Pipeline([('countVec', countVec), ('linSVC', clf)])\n",
    "cV_mNB.set_params(linSVC__random_state=42, linSVC__max_iter=20000).fit(X_train, y_train)\n",
    "cV_mNB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tag = []\n",
    "k = 0\n",
    "for text in texts_stemmed:\n",
    "    txt = []\n",
    "    sents = sent_tokenize(text)\n",
    "    bool = True\n",
    "    for sent in sents:\n",
    "        if bool:\n",
    "            txt = pos_tag(word_tokenize(sent))\n",
    "            bool = False\n",
    "        else:\n",
    "            txt += pos_tag(word_tokenize(sent))\n",
    "    texts_tag.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('plot', 'NN'), (':', ':'), ('two', 'CD'), ('teen', 'NN'), ('coupl', 'NNS'), ('go', 'VBP'), ('to', 'TO'), ('a', 'DT'), ('church', 'NN'), ('parti', 'NN'), (',', ','), ('drink', 'NN'), ('and', 'CC'), ('then', 'RB'), ('drive', 'NN'), ('.', '.'), ('they', 'PRP'), ('get', 'VBP'), ('into', 'IN'), ('an', 'DT'), ('accid', 'NN'), ('.', '.'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('guy', 'NN'), ('die', 'NN'), (',', ','), ('but', 'CC'), ('his', 'PRP$'), ('girlfriend', 'NN'), ('continu', 'NN'), ('to', 'TO'), ('see', 'VB'), ('him', 'PRP'), ('in', 'IN'), ('her', 'PRP$'), ('life', 'NN'), (',', ','), ('and', 'CC'), ('has', 'VBZ'), ('nightmar', 'VBN'), ('.', '.'), ('what', 'WP'), ('the', 'DT'), ('deal', 'NN'), ('?', '.'), ('watch', 'VB'), ('the', 'DT'), ('movi', 'NN'), ('and', 'CC'), ('``', '``'), ('sorta', 'JJ'), ('``', '``'), ('find', 'VB'), ('out', 'RP'), ('.', '.'), ('.', '.'), ('.', '.'), ('critiqu', 'NN'), (':', ':'), ('a', 'DT'), ('mind-fuck', 'JJ'), ('movi', 'NN'), ('for', 'IN'), ('the', 'DT'), ('teen', 'JJ'), ('generat', 'NN'), ('that', 'WDT'), ('touch', 'NN'), ('on', 'IN'), ('a', 'DT'), ('veri', 'JJ'), ('cool', 'NN'), ('idea', 'NN'), (',', ','), ('but', 'CC'), ('present', 'JJ'), ('it', 'PRP'), ('in', 'IN'), ('a', 'DT'), ('veri', 'NN'), ('bad', 'JJ'), ('packag', 'NN'), ('.', '.'), ('which', 'WDT'), ('is', 'VBZ'), ('what', 'WP'), ('make', 'VB'), ('this', 'DT'), ('review', 'NN'), ('an', 'DT'), ('even', 'RB'), ('harder', 'RBR'), ('one', 'CD'), ('to', 'TO'), ('write', 'VB'), (',', ','), ('sinc', 'NN'), ('i', 'NN'), ('general', 'JJ'), ('applaud', 'NN'), ('film', 'NN'), ('which', 'WDT'), ('attempt', 'NN'), ('to', 'TO'), ('break', 'VB'), ('the', 'DT'), ('mold', 'NN'), (',', ','), ('mess', 'NN'), ('with', 'IN'), ('your', 'PRP$'), ('head', 'NN'), ('and', 'CC'), ('such', 'JJ'), ('(', '('), ('lost', 'VBN'), ('highway', 'NN'), ('&', 'CC'), ('memento', 'NN'), (')', ')'), (',', ','), ('but', 'CC'), ('there', 'EX'), ('are', 'VBP'), ('good', 'JJ'), ('and', 'CC'), ('bad', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('make', 'NN'), ('all', 'DT'), ('type', 'NN'), ('of', 'IN'), ('film', 'NN'), (',', ','), ('and', 'CC'), ('these', 'DT'), ('folk', 'NN'), ('just', 'RB'), ('did', 'VBD'), (\"n't\", 'RB'), ('snag', 'VB'), ('this', 'DT'), ('one', 'CD'), ('correct', 'NN'), ('.', '.'), ('they', 'PRP'), ('seem', 'VBP'), ('to', 'TO'), ('have', 'VB'), ('taken', 'VBN'), ('this', 'DT'), ('pretti', 'JJ'), ('neat', 'NN'), ('concept', 'NN'), (',', ','), ('but', 'CC'), ('execut', 'VBD'), ('it', 'PRP'), ('terribl', 'NN'), ('.', '.'), ('so', 'RB'), ('what', 'WP'), ('are', 'VBP'), ('the', 'DT'), ('problem', 'NN'), ('with', 'IN'), ('the', 'DT'), ('movi', 'NN'), ('?', '.'), ('well', 'RB'), (',', ','), ('it', 'PRP'), ('main', 'JJ'), ('problem', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('simpli', 'VBD'), ('too', 'RB'), ('jumbl', 'JJ'), ('.', '.'), ('it', 'PRP'), ('start', 'VBD'), ('off', 'IN'), ('``', '``'), ('normal', 'JJ'), ('``', '``'), ('but', 'CC'), ('then', 'RB'), ('downshift', 'VB'), ('into', 'IN'), ('this', 'DT'), ('``', '``'), ('fantasi', 'JJ'), ('``', '``'), ('world', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('you', 'PRP'), (',', ','), ('as', 'IN'), ('an', 'DT'), ('audienc', 'JJ'), ('member', 'NN'), (',', ','), ('have', 'VBP'), ('no', 'DT'), ('idea', 'NN'), ('what', 'WP'), ('go', 'VB'), ('on', 'IN'), ('.', '.'), ('there', 'EX'), ('are', 'VBP'), ('dream', 'NN'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('charact', 'JJ'), ('come', 'VBN'), ('back', 'RB'), ('from', 'IN'), ('the', 'DT'), ('dead', 'JJ'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('other', 'JJ'), ('who', 'WP'), ('look', 'VBP'), ('like', 'IN'), ('the', 'DT'), ('dead', 'JJ'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('strang', 'JJ'), ('apparit', 'NN'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('disappear', 'JJ'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('a', 'DT'), ('looooot', 'NN'), ('of', 'IN'), ('chase', 'JJ'), ('scene', 'NN'), (',', ','), ('there', 'EX'), ('are', 'VBP'), ('ton', 'NN'), ('of', 'IN'), ('weird', 'JJ'), ('thing', 'NN'), ('that', 'WDT'), ('happen', 'VB'), (',', ','), ('and', 'CC'), ('most', 'JJS'), ('of', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('simpli', 'JJ'), ('not', 'RB'), ('explain', 'VB'), ('.', '.'), ('now', 'RB'), ('i', 'VBZ'), ('person', 'NN'), ('do', 'VBP'), (\"n't\", 'RB'), ('mind', 'VB'), ('tri', 'NN'), ('to', 'TO'), ('unravel', 'VB'), ('a', 'DT'), ('film', 'NN'), ('everi', 'NN'), ('now', 'RB'), ('and', 'CC'), ('then', 'RB'), (',', ','), ('but', 'CC'), ('when', 'WRB'), ('all', 'DT'), ('it', 'PRP'), ('doe', 'VBZ'), ('is', 'VBZ'), ('give', 'JJ'), ('me', 'PRP'), ('the', 'DT'), ('same', 'JJ'), ('clue', 'NN'), ('over', 'IN'), ('and', 'CC'), ('over', 'RB'), ('again', 'RB'), (',', ','), ('i', 'JJ'), ('get', 'VBP'), ('kind', 'NN'), ('of', 'IN'), ('fed', 'VBN'), ('up', 'RP'), ('after', 'IN'), ('a', 'DT'), ('while', 'NN'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('this', 'DT'), ('film', 'NN'), ('biggest', 'JJS'), ('problem', 'NN'), ('.', '.'), ('it', 'PRP'), ('obvious', 'JJ'), ('got', 'VBD'), ('this', 'DT'), ('big', 'JJ'), ('secret', 'NN'), ('to', 'TO'), ('hide', 'VB'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('seem', 'VBP'), ('to', 'TO'), ('want', 'VB'), ('to', 'TO'), ('hide', 'VB'), ('it', 'PRP'), ('complet', 'VB'), ('until', 'IN'), ('it', 'PRP'), ('final', 'JJ'), ('five', 'CD'), ('minut', 'NN'), ('.', '.'), ('and', 'CC'), ('do', 'VBP'), ('they', 'PRP'), ('make', 'VB'), ('thing', 'NN'), ('entertain', 'NN'), (',', ','), ('thrill', 'NN'), ('or', 'CC'), ('even', 'RB'), ('engag', 'NNS'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('meantim', 'NN'), ('?', '.'), ('not', 'RB'), ('realli', 'VB'), ('.', '.'), ('the', 'DT'), ('sad', 'JJ'), ('part', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('arrow', 'NN'), ('and', 'CC'), ('i', 'VB'), ('both', 'DT'), ('dig', 'NN'), ('on', 'IN'), ('flick', 'NN'), ('like', 'IN'), ('this', 'DT'), (',', ','), ('so', 'IN'), ('we', 'PRP'), ('actual', 'JJ'), ('figur', 'VBD'), ('most', 'JJS'), ('of', 'IN'), ('it', 'PRP'), ('out', 'RP'), ('by', 'IN'), ('the', 'DT'), ('half-way', 'JJ'), ('point', 'NN'), (',', ','), ('so', 'IN'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('strang', 'NN'), ('after', 'IN'), ('that', 'DT'), ('did', 'VBD'), ('start', 'VB'), ('to', 'TO'), ('make', 'VB'), ('a', 'DT'), ('littl', 'JJ'), ('bit', 'NN'), ('of', 'IN'), ('sens', 'NNS'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('still', 'RB'), ('did', 'VBD'), (\"n't\", 'RB'), ('the', 'DT'), ('make', 'VB'), ('the', 'DT'), ('film', 'NN'), ('all', 'PDT'), ('that', 'IN'), ('more', 'JJR'), ('entertain', 'NN'), ('.', '.'), ('i', 'NN'), ('guess', 'VBP'), ('the', 'DT'), ('bottom', 'JJ'), ('line', 'NN'), ('with', 'IN'), ('movi', 'NN'), ('like', 'IN'), ('this', 'DT'), ('is', 'VBZ'), ('that', 'IN'), ('you', 'PRP'), ('should', 'MD'), ('alway', 'VB'), ('make', 'VB'), ('sure', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('audienc', 'NN'), ('is', 'VBZ'), ('``', '``'), ('into', 'IN'), ('it', 'PRP'), ('``', '``'), ('even', 'RB'), ('befor', 'IN'), ('they', 'PRP'), ('are', 'VBP'), ('given', 'VBN'), ('the', 'DT'), ('secret', 'JJ'), ('password', 'NN'), ('to', 'TO'), ('enter', 'VB'), ('your', 'PRP$'), ('world', 'NN'), ('of', 'IN'), ('understand', 'NN'), ('.', '.'), ('i', 'JJ'), ('mean', 'NN'), (',', ','), ('show', 'VBP'), ('melissa', 'JJ'), ('sagemil', 'NN'), ('run', 'VB'), ('away', 'RB'), ('from', 'IN'), ('vision', 'NN'), ('for', 'IN'), ('about', 'IN'), ('20', 'CD'), ('minut', 'NNS'), ('throughout', 'IN'), ('the', 'DT'), ('movi', 'NN'), ('is', 'VBZ'), ('just', 'RB'), ('plain', 'JJ'), ('lazi', 'NN'), ('!', '.'), ('!', '.'), ('okay', 'RB'), (',', ','), ('we', 'PRP'), ('get', 'VBP'), ('it', 'PRP'), ('.', '.'), ('.', '.'), ('.', '.'), ('there', 'EX'), ('are', 'VBP'), ('peopl', 'JJ'), ('chase', 'NN'), ('her', 'PRP$'), ('and', 'CC'), ('we', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('know', 'VB'), ('who', 'WP'), ('they', 'PRP'), ('are', 'VBP'), ('.', '.'), ('do', 'VBP'), ('we', 'PRP'), ('realli', 'VB'), ('need', 'VBP'), ('to', 'TO'), ('see', 'VB'), ('it', 'PRP'), ('over', 'IN'), ('and', 'CC'), ('over', 'RB'), ('again', 'RB'), ('?', '.'), ('how', 'WRB'), ('about', 'RB'), ('give', 'VBP'), ('us', 'PRP'), ('differ', 'VBP'), ('scene', 'NN'), ('offer', 'VBP'), ('further', 'JJ'), ('insight', 'NN'), ('into', 'IN'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('strang', 'NN'), ('go', 'VBP'), ('down', 'RP'), ('in', 'IN'), ('the', 'DT'), ('movi', 'NN'), ('?', '.'), ('appar', 'NN'), (',', ','), ('the', 'DT'), ('studio', 'NN'), ('took', 'VBD'), ('this', 'DT'), ('film', 'NN'), ('away', 'RB'), ('from', 'IN'), ('it', 'PRP'), ('director', 'NN'), ('and', 'CC'), ('chop', 'NN'), ('it', 'PRP'), ('up', 'RP'), ('themselv', 'NN'), (',', ','), ('and', 'CC'), ('it', 'PRP'), ('show', 'VBP'), ('.', '.'), ('there', 'RB'), ('might', 'MD'), (\"'\", \"''\"), ('v', 'RB'), ('been', 'VBN'), ('a', 'DT'), ('pretti', 'JJ'), ('decent', 'NN'), ('teen', 'JJ'), ('mind-fuck', 'JJ'), ('movi', 'NN'), ('in', 'IN'), ('here', 'RB'), ('somewher', 'NN'), (',', ','), ('but', 'CC'), ('i', 'VBZ'), ('guess', 'VBP'), ('``', '``'), ('the', 'DT'), ('suit', 'NN'), ('``', '``'), ('decid', 'NN'), ('that', 'WDT'), ('turn', 'VBP'), ('it', 'PRP'), ('into', 'IN'), ('a', 'DT'), ('music', 'NN'), ('video', 'NN'), ('with', 'IN'), ('littl', 'JJ'), ('edg', 'NN'), (',', ','), ('would', 'MD'), ('make', 'VB'), ('more', 'JJR'), ('sens', 'NNS'), ('.', '.'), ('the', 'DT'), ('actor', 'NN'), ('are', 'VBP'), ('pretti', 'RB'), ('good', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('most', 'JJS'), ('part', 'NN'), (',', ','), ('although', 'IN'), ('wes', 'JJ'), ('bentley', 'NN'), ('just', 'RB'), ('seem', 'VB'), ('to', 'TO'), ('be', 'VB'), ('play', 'VB'), ('the', 'DT'), ('exact', 'JJ'), ('same', 'JJ'), ('charact', 'NN'), ('that', 'IN'), ('he', 'PRP'), ('did', 'VBD'), ('in', 'IN'), ('american', 'JJ'), ('beauti', 'NN'), (',', ','), ('onli', 'NN'), ('in', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('neighborhood', 'NN'), ('.', '.'), ('but', 'CC'), ('my', 'PRP$'), ('biggest', 'JJS'), ('kudo', 'NN'), ('go', 'VBP'), ('out', 'RP'), ('to', 'TO'), ('sagemil', 'VB'), (',', ','), ('who', 'WP'), ('hold', 'VBP'), ('her', 'PRP$'), ('own', 'JJ'), ('throughout', 'IN'), ('the', 'DT'), ('entir', 'NN'), ('film', 'NN'), (',', ','), ('and', 'CC'), ('actual', 'JJ'), ('has', 'VBZ'), ('you', 'PRP'), ('feel', 'VBP'), ('her', 'PRP$'), ('charact', 'NN'), ('unravel', 'NN'), ('.', '.'), ('overal', 'JJ'), (',', ','), ('the', 'DT'), ('film', 'NN'), ('does', 'VBZ'), (\"n't\", 'RB'), ('stick', 'VB'), ('becaus', 'VB'), ('it', 'PRP'), ('does', 'VBZ'), (\"n't\", 'RB'), ('entertain', 'VB'), (',', ','), ('it', 'PRP'), ('confus', 'VBZ'), (',', ','), ('it', 'PRP'), ('rare', 'JJ'), ('excit', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('feel', 'VB'), ('pretti', 'JJ'), ('redund', 'NN'), ('for', 'IN'), ('most', 'JJS'), ('of', 'IN'), ('it', 'PRP'), ('runtim', 'VBZ'), (',', ','), ('despit', 'VB'), ('a', 'DT'), ('pretti', 'NN'), ('cool', 'JJ'), ('end', 'NN'), ('and', 'CC'), ('explan', 'NN'), ('to', 'TO'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('crazi', 'NN'), ('that', 'WDT'), ('came', 'VBD'), ('befor', 'IN'), ('it', 'PRP'), ('.', '.'), ('oh', 'UH'), (',', ','), ('and', 'CC'), ('by', 'IN'), ('the', 'DT'), ('way', 'NN'), (',', ','), ('this', 'DT'), ('is', 'VBZ'), ('not', 'RB'), ('a', 'DT'), ('horror', 'NN'), ('or', 'CC'), ('teen', 'JJ'), ('slasher', 'JJR'), ('flick', 'NN'), ('.', '.'), ('.', '.'), ('.', '.'), ('it', 'PRP'), ('just', 'RB'), ('packag', 'VB'), ('to', 'TO'), ('look', 'VB'), ('that', 'DT'), ('way', 'NN'), ('becaus', 'NN'), ('someon', 'NN'), ('is', 'VBZ'), ('appar', 'JJ'), ('assum', 'NN'), ('that', 'IN'), ('the', 'DT'), ('genr', 'NN'), ('is', 'VBZ'), ('still', 'RB'), ('hot', 'JJ'), ('with', 'IN'), ('the', 'DT'), ('kid', 'NN'), ('.', '.'), ('it', 'PRP'), ('also', 'RB'), ('wrap', 'VBD'), ('product', 'NN'), ('two', 'CD'), ('year', 'NN'), ('ago', 'RB'), ('and', 'CC'), ('has', 'VBZ'), ('been', 'VBN'), ('sit', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('shelv', 'NN'), ('ever', 'RB'), ('sinc', 'RB'), ('.', '.'), ('whatev', 'NN'), ('.', '.'), ('.', '.'), ('.', '.'), ('skip', 'NN'), ('it', 'PRP'), ('!', '.'), ('where', 'WRB'), ('joblo', 'NN'), ('come', 'VB'), ('from', 'IN'), ('?', '.'), ('a', 'DT'), ('nightmar', 'NN'), ('of', 'IN'), ('elm', 'JJ'), ('street', 'NN'), ('3', 'CD'), ('(', '('), ('7/10', 'CD'), (')', ')'), ('-', ':'), ('blair', 'NN'), ('witch', 'NN'), ('2', 'CD'), ('(', '('), ('7/10', 'CD'), (')', ')'), ('-', ':'), ('the', 'DT'), ('crow', 'NN'), ('(', '('), ('9/10', 'CD'), (')', ')'), ('-', ':'), ('the', 'DT'), ('crow', 'NN'), (':', ':'), ('salvat', 'NN'), ('(', '('), ('4/10', 'CD'), (')', ')'), ('-', ':'), ('lost', 'VBN'), ('highway', 'NN'), ('(', '('), ('10/10', 'CD'), (')', ')'), ('-', ':'), ('memento', 'NN'), ('(', '('), ('10/10', 'CD'), (')', ')'), ('-', ':'), ('the', 'DT'), ('other', 'JJ'), ('(', '('), ('9/10', 'CD'), (')', ')'), ('-', ':'), ('stir', 'NN'), ('of', 'IN'), ('echo', 'NN'), ('(', '('), ('8/10', 'CD'), (')', ')')]\n"
     ]
    }
   ],
   "source": [
    "print(texts_tag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
